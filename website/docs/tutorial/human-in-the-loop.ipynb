{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbC8QOWX1WlM"
      },
      "source": [
        "# Allowing Human Feedback in Agents\n",
        "\n",
        "In the last two chapters we introduced the `ConversableAgent` class and showed how you can use it to create autonomous (`human_input_mode=NEVER`) agents that can accomplish tasks. We also showed how to properly terminate a conversation between agents.\n",
        "\n",
        "But many applications may require putting humans in-the-loop with agents. For example, to allow human feedback to steer agents in the right direction, specify goals, etc. In this chapter, we will show how AutoGen supports human intervention.\n",
        "\n",
        "In AutoGen's `ConversableAgent`, the human-in-the-loop component sits in front\n",
        "of the auto-reply components. It can intercept the incoming messages and\n",
        "decide whether to pass them to the auto-reply components or to provide\n",
        "human feedback. The figure below illustrates the design.\n",
        "\n",
        "```{=mdx}\n",
        "![Human in the loop](./assets/human-in-the-loop.png)\n",
        "```\n",
        "\n",
        "The human-in-the-loop component can be customized through the `human_input_mode` parameter.\n",
        "We will show you how to use it in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmiHSYvx1WlO"
      },
      "source": [
        "## Human Input Modes\n",
        "\n",
        "Currently AutoGen supports three modes for human input. The mode is specified through\n",
        "the `human_input_mode` argument of the `ConversableAgent`. The three modes are:\n",
        "\n",
        "1. `NEVER`: human input is never requested.\n",
        "2. `TERMINATE` (default): human input is only requested when a termination condition is\n",
        "    met. Note that in this mode if the human chooses to intercept and reply, the conversation continues\n",
        "    and the counter used by `max_consecutive_auto_reply` is reset.\n",
        "3. `ALWAYS`: human input is always requested and the human can choose to skip and trigger an auto-reply,\n",
        "    intercept and provide feedback, or terminate the conversation. Note that in this mode\n",
        "    termination based on `max_consecutive_auto_reply` is ignored.\n",
        "\n",
        "The previous chapters already showed many examples of the cases when `human_input_mode` is `NEVER`.\n",
        "Below we show one such example again and then show the differences when this mode is set to `ALWAYS` and `TERMINATE` instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njCsG9mS1WlO"
      },
      "source": [
        "## Human Input Mode = `NEVER`\n",
        "\n",
        "In this mode, human input is never requested and the termination conditions\n",
        "are used to terminate.\n",
        "This mode is useful when you want your agents to act fully autonomously.\n",
        "\n",
        "Here is an example of using this mode to run a simple guess-a-number game between\n",
        "two agents, the termination message is set to check for the\n",
        "number that is the correct guess."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install autogen"
      ],
      "metadata": {
        "id": "73j3bI3P10ix",
        "outputId": "6a1233dd-ec77-462f-9003-5a6208877304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen\n",
            "  Downloading autogen-0.9.6-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ag2==0.9.6 (from autogen)\n",
            "  Downloading ag2-0.9.6-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (4.9.0)\n",
            "Collecting asyncer==0.0.8 (from ag2==0.9.6->autogen)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting diskcache (from ag2==0.9.6->autogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from ag2==0.9.6->autogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (2.11.7)\n",
            "Collecting python-dotenv (from ag2==0.9.6->autogen)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.6->autogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.6->autogen) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.6->autogen) (4.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.6->autogen) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.6->autogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.6->autogen) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.6->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.6->autogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.6->autogen) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.6->autogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.6->autogen) (2.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.6->autogen) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->ag2==0.9.6->autogen) (3.4.2)\n",
            "Downloading autogen-0.9.6-py3-none-any.whl (13 kB)\n",
            "Downloading ag2-0.9.6-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.2/859.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, diskcache, docker, asyncer, ag2, autogen\n",
            "Successfully installed ag2-0.9.6 asyncer-0.0.8 autogen-0.9.6 diskcache-5.6.3 docker-7.1.0 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aHu0MWPf1WlP",
        "outputId": "25a834d5-920b-417c-ec66-202631885637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "I have a number between 1 and 100. Guess it!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 50?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too low.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 75?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 62?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 56?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 53?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (f1acc0ac-650a-4cea-bfe8-9a3abf2b6f71): Termination message condition on agent 'agent_with_number' met\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from autogen import ConversableAgent\n",
        "from google.colab import userdata\n",
        "\n",
        "agent_with_number = ConversableAgent(\n",
        "    \"agent_with_number\",\n",
        "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
        "    \"number 53 in your mind, and I will try to guess it. \"\n",
        "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
        "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": userdata.get('OPENAI_API_KEY')}]},\n",
        "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
        "    human_input_mode=\"NEVER\",  # never ask for human input\n",
        ")\n",
        "\n",
        "agent_guess_number = ConversableAgent(\n",
        "    \"agent_guess_number\",\n",
        "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
        "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
        "    \"you should guess a higher number. \",\n",
        "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": userdata.get('OPENAI_API_KEY')}]},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "result = agent_with_number.initiate_chat(\n",
        "    agent_guess_number,\n",
        "    message=\"I have a number between 1 and 100. Guess it!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELe1A3Ue1WlQ"
      },
      "source": [
        "Yay! The game is over. The guessing agent got the number correctly\n",
        "using binary search -- very efficient!\n",
        "You can see that the conversation was terminated after the guessing agent\n",
        "said the correct number, which triggered\n",
        "the message-based termination condition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io2-ycgW1WlQ"
      },
      "source": [
        "## Human Input Mode = `ALWAYS`\n",
        "\n",
        "In this mode, human input is always requested and the human can choose to skip,\n",
        "intercept , or terminate the conversation.\n",
        "Let us see this mode in action by playing the same game as before with the agent with the number, but this time\n",
        "participating in the game as a human.\n",
        "We will be the agent that is guessing the number, and play against the agent\n",
        "with the number from before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JUPPCRo81WlQ",
        "outputId": "99589353-53fb-49a3-a157-452cb97deb72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "human_proxy (to agent_with_number):\n",
            "\n",
            "10\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to human_proxy):\n",
            "\n",
            "Too low.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 60\n",
            "human_proxy (to agent_with_number):\n",
            "\n",
            "60\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to human_proxy):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 40\n",
            "human_proxy (to agent_with_number):\n",
            "\n",
            "40\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to human_proxy):\n",
            "\n",
            "Too low.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 55\n",
            "human_proxy (to agent_with_number):\n",
            "\n",
            "55\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to human_proxy):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 53\n",
            "human_proxy (to agent_with_number):\n",
            "\n",
            "53\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (9979ac0d-abe0-4b4a-b91a-1ad123ebba5d): Termination message condition on agent 'agent_with_number' met\n"
          ]
        }
      ],
      "source": [
        "human_proxy = ConversableAgent(\n",
        "    \"human_proxy\",\n",
        "    llm_config=False,  # no LLM used for human proxy\n",
        "    human_input_mode=\"ALWAYS\",  # always ask for human input\n",
        ")\n",
        "\n",
        "# Start a chat with the agent with number with an initial guess.\n",
        "result = human_proxy.initiate_chat(\n",
        "    agent_with_number,  # this is the same agent with the number as before\n",
        "    message=\"10\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmsM3TJG1WlQ"
      },
      "source": [
        "If you run the code above, you will be prompt to enter a response\n",
        "each time it is your turn to speak. You can see the human in the conversation\n",
        "was not very good at guessing the number... but hey the agent was nice enough\n",
        "to give out the number in the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xZhq_kY1WlR"
      },
      "source": [
        "## Human Input Mode = `TERMINATE`\n",
        "\n",
        "In this mode, human input is only requested when a termination condition is\n",
        "met. **If the human chooses to intercept and reply, the counter will be reset**; if\n",
        "the human chooses to skip, the automatic reply mechanism will be used; if the human\n",
        "chooses to terminate, the conversation will be terminated.\n",
        "\n",
        "Let us see this mode in action by playing the same game again, but this time\n",
        "the guessing agent will only have two chances to guess the number, and if it\n",
        "fails, the human will be asked to provide feedback,\n",
        "and the guessing agent gets two more chances.\n",
        "If the correct number is guessed eventually, the conversation will be terminated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXTOq3841WlR",
        "outputId": "a7fcca51-008e-439a-e785-c8a52adb840c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "I have a number between 1 and 100. Guess it!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 50?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too low.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 75?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 62?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "Too high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Is it 56?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: 53\n",
            "agent_with_number (to agent_guess_number):\n",
            "\n",
            "53\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guess_number (to agent_with_number):\n",
            "\n",
            "Ok. So, the number is 53.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "agent_with_number = ConversableAgent(\n",
        "    \"agent_with_number\",\n",
        "    system_message=\"You are playing a game of guess-my-number. \"\n",
        "    \"In the first game, you have the \"\n",
        "    \"number 53 in your mind, and I will try to guess it. \"\n",
        "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
        "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": userdata.get('OPENAI_API_KEY')}]},\n",
        "    max_consecutive_auto_reply=1,  # maximum number of consecutive auto-replies before asking for human input\n",
        "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
        "    human_input_mode=\"TERMINATE\",  # ask for human input until the game is terminated\n",
        ")\n",
        "\n",
        "agent_guess_number = ConversableAgent(\n",
        "    \"agent_guess_number\",\n",
        "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
        "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
        "    \"you should guess a higher number. \",\n",
        "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": userdata.get('OPENAI_API_KEY')}]},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "result = agent_with_number.initiate_chat(\n",
        "    agent_guess_number,\n",
        "    message=\"I have a number between 1 and 100. Guess it!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWsSFoy51WlR"
      },
      "source": [
        "In the previous conversation,\n",
        "\n",
        "1. When the agent guessed \"74\", the human said \"It is too high my friend.\"\n",
        "2. When the agent guessed \"55\", the human said \"still too high, but you are very close.\"\n",
        "3. When the agent guessed \"54\", the human said \"Almost there!\"\n",
        "\n",
        "Each time after one auto-reply from the agent with the number,\n",
        "the human was asked to provide feedback.\n",
        "Once the human provided feedback, the counter was reset.\n",
        "The conversation was terminated after the agent correctly guessed \"53\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF7fLg2D1WlR"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this chapter, we showed you how to use the human-in-the-loop component\n",
        "to provide human feedback to agent and to terminate conversation.\n",
        "We also showed you the different human input modes and how they affect\n",
        "the behavior of the human-in-the-loop component.\n",
        "\n",
        "The next chapter will be all about code executor -- the most powerful\n",
        "component second only to LLMs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "autogen",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}